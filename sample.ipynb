{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>br-icloud.com.br</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mp3raid.com/music/krizz_kaliko.html</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bopsecrets.org/rexroth/cr/1.htm</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.garage-pirenne.be/index.php?option=...</td>\n",
       "      <td>defacement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://adventure-nicaragua.net/index.php?optio...</td>\n",
       "      <td>defacement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651186</th>\n",
       "      <td>xbox360.ign.com/objects/850/850402.html</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651187</th>\n",
       "      <td>games.teamxbox.com/xbox-360/1860/Dead-Space/</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651188</th>\n",
       "      <td>www.gamespot.com/xbox360/action/deadspace/</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651189</th>\n",
       "      <td>en.wikipedia.org/wiki/Dead_Space_(video_game)</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651190</th>\n",
       "      <td>www.angelfire.com/goth/devilmaycrytonite/</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>651191 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      url        type\n",
       "0                                        br-icloud.com.br    phishing\n",
       "1                     mp3raid.com/music/krizz_kaliko.html      benign\n",
       "2                         bopsecrets.org/rexroth/cr/1.htm      benign\n",
       "3       http://www.garage-pirenne.be/index.php?option=...  defacement\n",
       "4       http://adventure-nicaragua.net/index.php?optio...  defacement\n",
       "...                                                   ...         ...\n",
       "651186            xbox360.ign.com/objects/850/850402.html    phishing\n",
       "651187       games.teamxbox.com/xbox-360/1860/Dead-Space/    phishing\n",
       "651188         www.gamespot.com/xbox360/action/deadspace/    phishing\n",
       "651189      en.wikipedia.org/wiki/Dead_Space_(video_game)    phishing\n",
       "651190          www.angelfire.com/goth/devilmaycrytonite/    phishing\n",
       "\n",
       "[651191 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main = pd.read_csv(\"malicious_phish.csv\")\n",
    "main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://1337x.to/torrent/1048648/American-Snipe...</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://1337x.to/torrent/1110018/Blackhat-2015-...</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://1337x.to/torrent/1122940/Blackhat-2015-...</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://1337x.to/torrent/1124395/Fast-and-Furio...</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://1337x.to/torrent/1145504/Avengers-Age-o...</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>http://www.ccent.com.au/index.php?view=article...</td>\n",
       "      <td>defacement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>http://www.ccent.com.au/index.php?option=com_c...</td>\n",
       "      <td>defacement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>http://www.ccent.com.au/index.php?option=com_m...</td>\n",
       "      <td>defacement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>http://www.ccent.com.au/index.php?view=article...</td>\n",
       "      <td>defacement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>http://www.ccent.com.au/index.php?option=com_c...</td>\n",
       "      <td>defacement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     url        type\n",
       "0      http://1337x.to/torrent/1048648/American-Snipe...      benign\n",
       "1      http://1337x.to/torrent/1110018/Blackhat-2015-...      benign\n",
       "2      http://1337x.to/torrent/1122940/Blackhat-2015-...      benign\n",
       "3      http://1337x.to/torrent/1124395/Fast-and-Furio...      benign\n",
       "4      http://1337x.to/torrent/1145504/Avengers-Age-o...      benign\n",
       "...                                                  ...         ...\n",
       "99995  http://www.ccent.com.au/index.php?view=article...  defacement\n",
       "99996  http://www.ccent.com.au/index.php?option=com_c...  defacement\n",
       "99997  http://www.ccent.com.au/index.php?option=com_m...  defacement\n",
       "99998  http://www.ccent.com.au/index.php?view=article...  defacement\n",
       "99999  http://www.ccent.com.au/index.php?option=com_c...  defacement\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define a list of file paths and corresponding types\n",
    "file_paths = [\n",
    "    (\"FinalDataset/URL/Benign_list_big_final.csv\", \"benign\"),\n",
    "    (\"FinalDataset/URL/DefacementSitesURLFiltered.csv\", \"defacement\"),\n",
    "    (\"FinalDataset/URL/Malware_dataset.csv\", \"malware\"),\n",
    "    (\"FinalDataset/URL/phishing_dataset.csv\", \"phishing\"),\n",
    "    (\"FinalDataset/URL/spam_dataset.csv\", \"spam\")\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store dataframes\n",
    "dfs = []\n",
    "\n",
    "# Iterate through the file paths and types\n",
    "for file_path, url_type in file_paths:\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path, header=None)\n",
    "    # Assign column names\n",
    "    df.columns = [\"url\"]\n",
    "    # Add a column for the URL type\n",
    "    df[\"type\"] = url_type\n",
    "    # Append the dataframe to the list\n",
    "    dfs.append(df)\n",
    "\n",
    "dfs.append(main)\n",
    "# Concatenate the list of dataframes into a single dataframe\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "merged_df.drop_duplicates(inplace=True)\n",
    "merged_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the merged dataframe\n",
    "merged_df.head(100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values before cleaning:\")\n",
    "print(merged_df.isnull().sum())\n",
    "\n",
    "# Drop rows with missing values (if any)\n",
    "merged_df = merged_df.dropna()\n",
    "\n",
    "# Encode labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "merged_df['label'] = le.fit_transform(merged_df['type'])\n",
    "\n",
    "# Clean URLs\n",
    "import re\n",
    "def clean_url(url):\n",
    "    url = re.sub(r'^https?://', '', url)  # Remove protocol\n",
    "    url = re.sub(r'www\\d*\\.', '', url)    # Remove www\n",
    "    url = url.split('/')[0]               # Keep domain\n",
    "    return url\n",
    "\n",
    "merged_df['clean_url'] = merged_df['url'].apply(clean_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class Distribution & Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot class distribution\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 6))\n",
    "merged_df['type'].value_counts().plot(kind='bar')\n",
    "plt.title(\"Class Distribution Before Balancing\")\n",
    "plt.savefig('class_distribution_before.png')\n",
    "plt.show()\n",
    "\n",
    "# Balance using SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF-IDF Vectorization (required for SMOTE on text data)\n",
    "tfidf = TfidfVectorizer(max_features=1000)\n",
    "X_tfidf = tfidf.fit_transform(merged_df['clean_url'])\n",
    "y = merged_df['label']\n",
    "\n",
    "# Split data first to avoid data leakage\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, stratify=y)\n",
    "\n",
    "# Apply SMOTE only on the training set\n",
    "smote = SMOTE()\n",
    "X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Plot balanced distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "pd.Series(y_train_bal).value_counts().plot(kind='bar')\n",
    "plt.title(\"Class Distribution After Balancing\")\n",
    "plt.savefig('class_distribution_after.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structural Features\n",
    "def extract_structural_features(url):\n",
    "    return {\n",
    "        'length': len(url),\n",
    "        'num_dots': url.count('.'),\n",
    "        'num_hyphens': url.count('-'),\n",
    "        'num_slash': url.count('/'),\n",
    "        'has_query': 1 if '?' in url else 0\n",
    "    }\n",
    "\n",
    "structural_features = merged_df['clean_url'].apply(extract_structural_features)\n",
    "structural_df = pd.DataFrame(structural_features.tolist())\n",
    "\n",
    "# Combine with TF-IDF\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "X_combined = hstack([X_tfidf, structural_df.values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split combined features\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, stratify=y)\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "print(f\"Random Forest Accuracy: {accuracy_score(y_test, rf_pred)}\")\n",
    "\n",
    "# XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "print(f\"XGBoost Accuracy: {accuracy_score(y_test, xgb_pred)}\")\n",
    "\n",
    "# LSTM (simplified example)\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(merged_df['clean_url'])\n",
    "sequences = tokenizer.texts_to_sequences(merged_df['clean_url'])\n",
    "X_seq = pad_sequences(sequences, maxlen=100)\n",
    "\n",
    "# Train LSTM (use GPU if available)\n",
    "from tensorflow.keras.models import Sequential\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=64),\n",
    "    LSTM(64),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_seq, merged_df['label'], epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization & Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay.from_estimator(rf, X_test, y_test)\n",
    "plt.title(\"Random Forest Confusion Matrix\")\n",
    "plt.savefig('confusion_matrix_rf.png')\n",
    "\n",
    "# Feature Importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(rf.feature_importances_)), rf.feature_importances_)\n",
    "plt.title(\"Feature Importance (Random Forest)\")\n",
    "plt.savefig('feature_importance.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM-Based Model (BERT) Integration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM-Based Model (BERT) Integration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT Fine-Tuning (LLM)\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "\n",
    "# Tokenize URLs\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "inputs = tokenizer(\n",
    "    merged_df['clean_url'].tolist(),\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=128,\n",
    "    return_tensors='tf'\n",
    ")\n",
    "\n",
    "# Prepare labels\n",
    "labels = tf.convert_to_tensor(merged_df['label'])\n",
    "\n",
    "# Split into train-test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    inputs['input_ids'], labels, test_size=0.2, stratify=labels\n",
    ")\n",
    "\n",
    "# Load BERT model\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5)\n",
    "\n",
    "# Compile and train\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=2, batch_size=16, validation_split=0.1)\n",
    "\n",
    "# Evaluate\n",
    "bert_pred = model.predict(X_test).logits.argmax(axis=1)\n",
    "print(f\"BERT Accuracy: {accuracy_score(y_test, bert_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
